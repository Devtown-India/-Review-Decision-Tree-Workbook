{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision Tree.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nghXNb5BqCGV",
        "colab_type": "text"
      },
      "source": [
        "### This tutorial is divided into following sections:\n",
        "\n",
        "\n",
        "1.   Implementing Decision Tree from scratch\n",
        "2.   Implementing Decision Tree using scikit-learn\n",
        "3.   Implementing Decision Tree using Tensorflow\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDBAU6hdqr88",
        "colab_type": "text"
      },
      "source": [
        "# Implementing Decision Tree from scratch\n",
        "### This section is divided into following parts:\n",
        "\n",
        "\n",
        "1.   Gini Index\n",
        "2.   Create Split\n",
        "3.   Build a Tree\n",
        "4.   Make a Precision\n",
        "5.   Use Case\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfekG9k8rKHy",
        "colab_type": "text"
      },
      "source": [
        "## Gini Index\n",
        "The Gini index is the name of the cost function used to evaluate splits in the dataset.\n",
        "\n",
        "A split in the dataset involves one input attribute and one value for that attribute. It can be used to divide training patterns into two groups of rows.\n",
        "\n",
        "A Gini score gives an idea of how good a split is by how mixed the classes are in the two groups created by the split. A perfect separation results in a Gini score of 0, whereas the worst case split that results in 50/50 classes in each group result in a Gini score of 0.5 (for a 2 class problem).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxlQTLJKvdwo",
        "colab_type": "text"
      },
      "source": [
        "The following is used to calculate gini index:\n",
        "\n",
        "1. We calculate proprotion of classes in each group=(count of class)/size of group\n",
        "2. gini index will be sum of are gini scores of class in each group = 1-sum(proportion*proportion)\n",
        "3. we weight gini score of each group by size gini= (1-sum(proportion*proportin))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne1KdcaW1tKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otGwVxs3p4Mq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the Gini index for a split dataset\n",
        "def gini_index(groups, classes):\n",
        "\t# count all samples at split point\n",
        "\tn_instances = float(sum([len(group) for group in groups]))\n",
        "\t# sum weighted Gini index for each group\n",
        "\tgini = 0.0\n",
        "\tfor group in groups:\n",
        "\t\tsize = float(len(group))\n",
        "\t\t# avoid divide by zero\n",
        "\t\tif size == 0:\n",
        "\t\t\tcontinue\n",
        "\t\tscore = 0.0\n",
        "\t\t# score the group based on the score for each class\n",
        "\t\tfor class_val in classes:\n",
        "\t\t\tp = [row[-1] for row in group].count(class_val) / size\n",
        "\t\t\tscore += p * p\n",
        "\t\t# weight the group score by its relative size\n",
        "\t\tgini += (1.0 - score) * (size / n_instances)\n",
        "\treturn gini"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqmuSuCmqNhn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5e974b77-5a1f-4128-d005-2e19c641f9df"
      },
      "source": [
        "# test Gini values\n",
        "print(gini_index([[[1, 1], [1, 0]], [[1, 1], [1, 0]]], [0, 1]))\n",
        "print(gini_index([[[1, 0], [1, 0]], [[1, 1], [1, 1]]], [0, 1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr4z9cfd0OZ5",
        "colab_type": "text"
      },
      "source": [
        "## Create A Split\n",
        "Creating a split invloves three steps:\n",
        "1. Calculating gini score\n",
        "2. Splitting Dataset\n",
        "3. Evaluating Split\n",
        "\n",
        "We saw about gini score in previous section\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtTMY0Q13eAR",
        "colab_type": "text"
      },
      "source": [
        "### Splitting Dataset:\n",
        "It is as simple as its name.We need index of attribute,dataset and value we are splitting with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvu02JA6xDef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split a dataset based on an attribute and an attribute value\n",
        "def test_split(index, value, dataset):\n",
        "\tleft, right = list(), list()\n",
        "\tfor row in dataset:\n",
        "\t\tif row[index] < value:\n",
        "\t\t\tleft.append(row)\n",
        "\t\telse:\n",
        "\t\t\tright.append(row)\n",
        "\treturn left, right"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3_VLCTZ1Lbj",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating split:\n",
        "This is an exhaustive and greedy algorithm. We will use dictionary to store data as we can store data using names.We will store index of attribute,value of attribute and two groups of data split of best gini score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhVR6VR21KPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select the best split point for a dataset\n",
        "def get_split(dataset):\n",
        "\tclass_values = list(set(row[-1] for row in dataset))\n",
        "\tb_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
        "\tfor index in range(len(dataset[0])-1):\n",
        "\t\tfor row in dataset:\n",
        "\t\t\tgroups = test_split(index, row[index], dataset)\n",
        "\t\t\tgini = gini_index(groups, class_values)\n",
        "\t\t\tif gini < b_score:\n",
        "\t\t\t\tb_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
        "\treturn {'index':b_index, 'value':b_value, 'groups':b_groups}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJRVRzx84eyB",
        "colab_type": "text"
      },
      "source": [
        "## Build A Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqQvSSg24qjR",
        "colab_type": "text"
      },
      "source": [
        "Building a tree may be divided into 3 main parts:\n",
        "\n",
        "1. Terminal Nodes.\n",
        "2. Recursive Splitting.\n",
        "3. Building a Tree.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l07LhEpr6wgN",
        "colab_type": "text"
      },
      "source": [
        "### Termial Nodes:\n",
        "We need to decide when to stop growing a tree\n",
        "\n",
        "We can do that using the depth and the number of rows that the node is responsible for in the training dataset.\n",
        "\n",
        "\n",
        "*   Maximum Tree Depth. This is the maximum number of nodes from the root node of the tree. Once a maximum depth of the tree is met, we must stop splitting adding new nodes. Deeper trees are more complex and are more likely to overfit the training data.\n",
        "*   Minimum Node Records. This is the minimum number of training patterns that a given node is responsible for. Once at or below this minimum, we must stop splitting and adding new nodes. Nodes that account for too few training patterns are expected to be too specific and are likely to overfit the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4d5aq2e3Cu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a terminal node value\n",
        "def to_terminal(group):\n",
        "\toutcomes = [row[-1] for row in group]\n",
        "\treturn max(set(outcomes), key=outcomes.count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RhvqMdas9o0",
        "colab_type": "text"
      },
      "source": [
        "### Recursive Splitting:\n",
        "Building a decision tree involves calling the above developed get_split() function over and over again on the groups created for each node.\n",
        "\n",
        "This function is best explained in steps:\n",
        "\n",
        "1. Firstly, the two groups of data split by the node are extracted for use and deleted from the node. As we work on these groups the node no longer requires access to these data.\n",
        "2. Next, we check if either left or right group of rows is empty and if so we create a terminal node using what records we do have.\n",
        "3. We then check if we have reached our maximum depth and if so we create a terminal node.\n",
        "4. We then process the left child, creating a terminal node if the group of rows is too small, otherwise creating and adding the left node in a depth first fashion until the bottom of the tree is reached on this branch.\n",
        "5. The right side is then processed in the same manner, as we rise back up the constructed tree to the root.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgPe99jY7zYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create child splits for a node or make terminal\n",
        "def split(node, max_depth, min_size, depth):\n",
        "\tleft, right = node['groups']\n",
        "\tdel(node['groups'])\n",
        "\t# check for a no split\n",
        "\tif not left or not right:\n",
        "\t\tnode['left'] = node['right'] = to_terminal(left + right)\n",
        "\t\treturn\n",
        "\t# check for max depth\n",
        "\tif depth >= max_depth:\n",
        "\t\tnode['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
        "\t\treturn\n",
        "\t# process left child\n",
        "\tif len(left) <= min_size:\n",
        "\t\tnode['left'] = to_terminal(left)\n",
        "\telse:\n",
        "\t\tnode['left'] = get_split(left)\n",
        "\t\tsplit(node['left'], max_depth, min_size, depth+1)\n",
        "\t# process right child\n",
        "\tif len(right) <= min_size:\n",
        "\t\tnode['right'] = to_terminal(right)\n",
        "\telse:\n",
        "\t\tnode['right'] = get_split(right)\n",
        "\t\tsplit(node['right'], max_depth, min_size, depth+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dh4co3jphRj",
        "colab_type": "text"
      },
      "source": [
        "### Building A Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zevY6xb3pVR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Build a decision tree\n",
        "def build_tree(train, max_depth, min_size):\n",
        "\troot = get_split(train)\n",
        "\tsplit(root, max_depth, min_size, 1)\n",
        "\treturn root"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T79p6ra9p5t-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "55548d16-f2d5-4ab0-e3b7-72c3503a63df"
      },
      "source": [
        "#Print a decision tree\n",
        "def print_tree(node, depth=0):\n",
        "\tif isinstance(node, dict):\n",
        "\t\tprint('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
        "\t\tprint_tree(node['left'], depth+1)\n",
        "\t\tprint_tree(node['right'], depth+1)\n",
        "\telse:\n",
        "\t\tprint('%s[%s]' % ((depth*' ', node)))\n",
        "\n",
        "dataset = [[2.7,1.2,0],\n",
        "\t[1.728,1.1,0],\n",
        "\t[3.678,2.8,0],\n",
        "\t[3.961,2.6,0],\n",
        "\t[2.999,2.2,0],\n",
        "\t[7.497,3.1,1],\n",
        "\t[9.203,3.3,1],\n",
        "\t[7.444,0.4,1],\n",
        "\t[10.12,3.2,1],\n",
        "\t[6.642,3.3,1]]\n",
        "tree = build_tree(dataset, 1, 1)\n",
        "print_tree(tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[X1 < 6.642]\n",
            " [0]\n",
            " [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jmu_iA7BqZtl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "f0fff54f-c5db-447a-bedb-d859ba64cd54"
      },
      "source": [
        "tree = build_tree(dataset,2,1)\n",
        "print_tree(tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[X1 < 6.642]\n",
            " [X1 < 2.700]\n",
            "  [0]\n",
            "  [0]\n",
            " [X1 < 7.497]\n",
            "  [1]\n",
            "  [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1cvAtqNqiCr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "67049d8d-ac10-4a54-b588-bcb392cf41ff"
      },
      "source": [
        "tree = build_tree(dataset,3,1)\n",
        "print_tree(tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[X1 < 6.642]\n",
            " [X1 < 2.700]\n",
            "  [0]\n",
            "  [X1 < 2.700]\n",
            "   [0]\n",
            "   [0]\n",
            " [X1 < 7.497]\n",
            "  [X1 < 7.444]\n",
            "   [1]\n",
            "   [1]\n",
            "  [X1 < 7.497]\n",
            "   [1]\n",
            "   [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV7Ld6s8s1RJ",
        "colab_type": "text"
      },
      "source": [
        "## Make A Prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMNwuJ7Bqoq_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f51d33c-6b84-49ea-8e1c-90228e02680e"
      },
      "source": [
        "#Make a prediction with a decision tree\n",
        "def predict(node,dataset):\n",
        "\tresults=np.array([0]*len(dataset))\n",
        "  \n",
        "\tfor i,row in enumerate(dataset):\n",
        "\t\tresults[i]=get_prediction(node,row)\n",
        "\t\n",
        "\treturn results\n",
        "\n",
        "def get_prediction(node, row):\n",
        "\tif row[node['index']] < node['value']:\n",
        "\t\tif isinstance(node['left'], dict):\n",
        "\t\t\treturn get_prediction(node['left'], row)\n",
        "\t\telse:\n",
        "\t\t\treturn node['left']\n",
        "\telse:\n",
        "\t\tif isinstance(node['right'], dict):\n",
        "\t\t\treturn get_prediction(node['right'], row)\n",
        "\t\telse:\n",
        "\t\t\treturn node['right']\n",
        "\n",
        "dataset=np.array([[2.7,1.2,0],\n",
        "\t[1.728,1.1,0],\n",
        "\t[3.678,2.8,0],\n",
        "\t[3.961,2.6,0],\n",
        "\t[2.999,2.2,0],\n",
        "\t[7.497,3.1,1],\n",
        "\t[9.203,3.3,1],\n",
        "\t[7.444,0.4,1],\n",
        "\t[10.12,3.2,1],\n",
        "\t[6.642,3.3,1]])\n",
        "\n",
        "stump = {'index': 0, 'right': 1, 'value': 6.642287351, 'left': 0}\n",
        "results=predict(stump,dataset)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iZLtXwJquMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecisionTreeClassifier():\n",
        "\n",
        "  def __init__(self,max_depth,depth=1,min_size=1):\n",
        "    self.max_depth=max_depth\n",
        "    self.depth=depth\n",
        "    self.min_size=min_size\n",
        "\n",
        "  def fit(self,x,y):\n",
        "    self.x=x\n",
        "    self.y=y\n",
        "\n",
        "    self.train=np.concatenate((x,y),axis=1)\n",
        "    self.build_tree(self.train,self.max_depth,self.min_size)\n",
        "\n",
        "  def gini_index(self,groups, classes):\n",
        "    n_instances = float(sum([len(group) for group in groups]))\n",
        "    \n",
        "    gini = 0.0\n",
        "    for group in groups:\n",
        "      size = float(len(group))\n",
        "      if size == 0:\n",
        "        continue\n",
        "      score = 0.0\n",
        "      for class_val in classes:\n",
        "        p = [row[-1] for row in group].count(class_val) / size\n",
        "        score += p * p\n",
        "      gini += (1.0 - score) * (size / n_instances)\n",
        "    return gini\n",
        "\n",
        "  def test_split(self,index, value, dataset):\n",
        "    left, right = list(), list()\n",
        "    for row in dataset:\n",
        "      if row[index] < value:\n",
        "        left.append(row)\n",
        "      else:\n",
        "        right.append(row)\n",
        "    return left, right\n",
        "\n",
        "  def get_split(self,dataset):\n",
        "    class_values = list(set(row[-1] for row in dataset))\n",
        "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
        "    for index in range(len(dataset[0])-1):\n",
        "      for row in dataset:\n",
        "        groups = self.test_split(index, row[index], dataset)\n",
        "        gini = self.gini_index(groups, class_values)\n",
        "        if gini < b_score:\n",
        "          b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
        "    return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
        "\n",
        "  def to_terminal(self,group):\n",
        "    outcomes = [row[-1] for row in group]\n",
        "    return max(set(outcomes), key=outcomes.count)\n",
        "\n",
        "  def split(self,node, max_depth, min_size, depth):\n",
        "    left, right = node['groups']\n",
        "    del(node['groups'])\n",
        "   \n",
        "    if not left or not right:\n",
        "      node['left'] = node['right'] = self.to_terminal(left + right)\n",
        "      return\n",
        "   \n",
        "    if depth >= max_depth:\n",
        "      node['left'], node['right'] = self.to_terminal(left), self.to_terminal(right)\n",
        "      return\n",
        "   \n",
        "    if len(left) <= min_size:\n",
        "      node['left'] = self.to_terminal(left)\n",
        "    else:\n",
        "      node['left'] = self.get_split(left)\n",
        "      self.split(node['left'], max_depth, min_size, depth+1)\n",
        "   \n",
        "    if len(right) <= min_size:\n",
        "      node['right'] = self.to_terminal(right)\n",
        "    else:\n",
        "      node['right'] = self.get_split(right)\n",
        "      self.split(node['right'], max_depth, min_size, depth+1)\n",
        "    \n",
        "\n",
        "  def build_tree(self,train, max_depth, min_size):\n",
        "    self.node = self.get_split(train)\n",
        "    self.split(self.node, max_depth, min_size, 1)\n",
        "\n",
        "\n",
        "  def predict(self,x):\n",
        "    results=np.array([0]*len(x))\n",
        "\n",
        "    for i,row in enumerate(x):\n",
        "      results[i]=self._get_prediction(self.node,row)\n",
        "\n",
        "    return results\n",
        "\n",
        "  def _get_prediction(self, node, row):\n",
        "    if row[node['index']] < node['value']:\n",
        "      if isinstance(node['left'], dict):\n",
        "        return self._get_prediction(node['left'], row)\n",
        "      else:\n",
        "        return node['left']\n",
        "    else:\n",
        "      if isinstance(node['right'], dict):\n",
        "        return self._get_prediction(node['right'], row)\n",
        "      else:\n",
        "        return node['right']\n",
        "\n",
        "    def printtree(self, depth=0):\n",
        "\t    if isinstance(self.node, dict):\n",
        "\t\t    print('%s[X%d < %.3f]' % ((depth*' ', (self.node['index']+1), self.node['value'])))\n",
        "\t\t    self.printtree(self.node['left'], depth+1)\n",
        "\t\t    self.printtree(self.node['right'], depth+1)\n",
        "\t    else:\n",
        "\t\t    print('%s[%s]' % ((depth*' ', self.node)))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fdvg9JA1afv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=np.array([[2.7,1.2],\n",
        "\t[1.728,1.1],\n",
        "\t[3.678,2.8],\n",
        "\t[3.961,2.6],\n",
        "\t[2.999,2.2],\n",
        "\t[7.497,3.1],\n",
        "\t[9.203,3.3],\n",
        "\t[7.444,0.4],\n",
        "\t[10.12,3.2],\n",
        "\t[6.642,3.3]])\n",
        "y=np.array([0,0,0,0,0,1,1,1,1,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDlJyyqotBsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree=DecisionTreeClassifier(max_depth=2)\n",
        "tree.fit(x,y.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHuaUI4c11OK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82f41a47-44a8-4a8b-a548-abd80ad54a8b"
      },
      "source": [
        "predict=tree.predict(x)\n",
        "predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYnPiMGCFhB9",
        "colab_type": "text"
      },
      "source": [
        "# Implementing Decision Tree using Scikit-Learn\n",
        "\n",
        "Scikit-Learn has inbuilt DecisionTreeClassifier model which can be imported by using following line of code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_owVAgFFrrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g8J7ByqF-SC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can instantiate DecisionTreeClassifier as follows:\n",
        "classifier=DecisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MivBpFEGTN7",
        "colab_type": "text"
      },
      "source": [
        "## Paramters/Arguments\n",
        "As we implemented DecisionTreeClassifier and it has some arguments or parameter such as max_depth,depth,min_size. Similarly scikit-learn's decision tree also has parameters.Some of them are as follows:\n",
        "\n",
        "1. criterion : 'gini' or 'entropy' criteria used for information gain\n",
        "2. max_depth : The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
        "\n",
        "3. min_samples_split : int or float, default=2\n",
        " The minimum number of samples required to split an internal node:\n",
        "If int, then consider min_samples_split as the minimum number.\n",
        "If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.\n",
        "\n",
        "\n",
        "4. min_samples_leaf : int or float, default=1\n",
        "The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n",
        "If int, then consider min_samples_leaf as the minimum number.\n",
        "If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node. \n",
        "\n",
        "5. max_leaf_nodes : int, default=None\n",
        "Grow a tree with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckBHwtszJpJx",
        "colab_type": "text"
      },
      "source": [
        "## Defining Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4Jrkjaa5bxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's define classifier with few of parameters\n",
        "classifier=DecisionTreeClassifier(criterion='gini',\n",
        "                                  max_depth=3,\n",
        "                                  min_samples_split=2,\n",
        "                                  min_samples_leaf=1,\n",
        "                                  max_leaf_nodes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-Ug07JIJs7n",
        "colab_type": "text"
      },
      "source": [
        "## Training Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykYGQ40nI_Hs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "faa7d23f-abc5-4d9c-9577-e666432c341e"
      },
      "source": [
        "#We can use fit() method to train classifier on our training set\n",
        "classifier.fit(x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=3, max_features=None, max_leaf_nodes=10,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb_FReeaJwvW",
        "colab_type": "text"
      },
      "source": [
        "## Using trained classifier for prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccHPMHHUJX7c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9b94a8b-91fb-45e3-d18c-13b8a051b7df"
      },
      "source": [
        "pred=classifier.predict(x)\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dslE6XU9DH39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po2p5iRBJ5aJ",
        "colab_type": "text"
      },
      "source": [
        "# Implementing Decision Tree using Tensorflow \n",
        "Tensorflow also contains inbuilt model for decision tree.The following line of code can be used to import it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9NmThu7Jczg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.estimator import BoostedTreesClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FH5F7XJLa5d",
        "colab_type": "text"
      },
      "source": [
        "## Defining Dataset parameters and building\n",
        "\n",
        "**Before** instantiating classifier we must give names to our feature columns because BoostedTreeClassifier accepts dataset in such a way. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKjUlhPdAaIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset parameters.\n",
        "num_classes = 2 # Total classes: greater or equal to $23,000, or not (See notes below).\n",
        "num_features = 2 # data features size.\n",
        "\n",
        "# Training parameters.\n",
        "max_steps = 200\n",
        "batch_size = 2\n",
        "learning_rate = 1.0\n",
        "l1_regul = 0.0\n",
        "l2_regul = 0.1\n",
        "\n",
        "# GBDT parameters.\n",
        "num_batches_per_layer = 4\n",
        "num_trees = 1\n",
        "max_depth = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atG4m5eOCjBC",
        "colab_type": "text"
      },
      "source": [
        "## Building Input Function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT1tMdTkMOW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the input function.\n",
        "train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
        "    x={'x': x}, y=y,\n",
        "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
        "\n",
        "test_train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
        "    x={'x': x}, y=y,\n",
        "    batch_size=batch_size, num_epochs=1, shuffle=False)\n",
        "\n",
        "\n",
        "# GBDT Models from TF Estimator requires 'feature_column' data format.\n",
        "feature_columns = [tf.feature_column.numeric_column(key='x', shape=(num_features,))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w74UOElaKuEV",
        "colab_type": "text"
      },
      "source": [
        "## Defining  Classifier:\n",
        "Let's instantiate classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIYHY1s_Ktbo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "04b5a4cf-8911-48ed-ae62-32a87a049c0e"
      },
      "source": [
        "classifier = tf.estimator.BoostedTreesClassifier(\n",
        "    n_batches_per_layer=num_batches_per_layer,\n",
        "    feature_columns=feature_columns, \n",
        "    n_classes=num_classes,\n",
        "    learning_rate=learning_rate, \n",
        "    n_trees=num_trees,\n",
        "    max_depth=max_depth,\n",
        "    l1_regularization=l1_regul, \n",
        "    l2_regularization=l2_regul\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp88kh1xis\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp88kh1xis', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKcqEBCrBjBR",
        "colab_type": "text"
      },
      "source": [
        "## Training Classifier:\n",
        "Training our classifier using train_input_fn which contains our training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4hL4tiBLKNP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "2b1b6b83-13ec-43d0-a170-5013bf9c247c"
      },
      "source": [
        "classifier.train(input_fn=train_input_fn,max_steps=max_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:Issue encountered when serializing resources.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'_Resource' object has no attribute 'name'\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py:906: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:Issue encountered when serializing resources.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'_Resource' object has no attribute 'name'\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp88kh1xis/model.ckpt.\n",
            "WARNING:tensorflow:Issue encountered when serializing resources.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'_Resource' object has no attribute 'name'\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 0.6931472, step = 0\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:loss = 0.044054892, step = 96 (0.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 298.652\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 160...\n",
            "INFO:tensorflow:Saving checkpoints for 160 into /tmp/tmp88kh1xis/model.ckpt.\n",
            "WARNING:tensorflow:Issue encountered when serializing resources.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'_Resource' object has no attribute 'name'\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 160...\n",
            "INFO:tensorflow:Loss for final step: 0.016127532.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.boosted_trees.BoostedTreesClassifier at 0x7fe8d9a36cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6InqBuJUByhZ",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating Classifier:\n",
        "We can evaluate our model using evaluate attribute of classifier<br>\n",
        "Note: Here we are evaluating classfir on training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCpOAzdkBGCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d21f7908-9e42-4f22-ead6-6e73710e49bc"
      },
      "source": [
        "evaluation=classifier.evaluate(test_train_input_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-08-12T04:58:41Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp88kh1xis/model.ckpt-160\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.39692s\n",
            "INFO:tensorflow:Finished evaluation at 2020-08-12-04:58:42\n",
            "INFO:tensorflow:Saving dict for global step 160: accuracy = 1.0, accuracy_baseline = 0.5, auc = 0.99999976, auc_precision_recall = 0.9999998, average_loss = 0.013007852, global_step = 160, label/mean = 0.5, loss = 0.013007852, precision = 1.0, prediction/mean = 0.4985648, recall = 1.0\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 160: /tmp/tmp88kh1xis/model.ckpt-160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xujRu2qjB_r1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0ebe757d-3cdf-4628-adc3-3771e435d57c"
      },
      "source": [
        "print(evaluation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'accuracy': 1.0, 'accuracy_baseline': 0.5, 'auc': 0.99999976, 'auc_precision_recall': 0.9999998, 'average_loss': 0.013007852, 'label/mean': 0.5, 'loss': 0.013007852, 'precision': 1.0, 'prediction/mean': 0.4985648, 'recall': 1.0, 'global_step': 160}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6DQKuCpCOMN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "2c268ebf-fddd-4225-cbe7-880e635fb3c0"
      },
      "source": [
        "#This gives us a generator object\n",
        "pred=classifier.predict(test_train_input_fn)\n",
        "\n",
        "#Converting generator objects to list then accessing class by using 'class_ids'\n",
        "results=list(pred)\n",
        "classes=[]\n",
        "for result in results:\n",
        "  classes.append(result['class_ids'][0])\n",
        "\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp88kh1xis/model.ckpt-160\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDT2kerFDUAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
